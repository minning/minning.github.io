<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>minning</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://minning.github.io/"/>
  <updated>2016-12-16T04:37:03.474Z</updated>
  <id>https://minning.github.io/</id>
  
  <author>
    <name>minning</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据挖掘讨论课《一》</title>
    <link href="https://minning.github.io/2016/12/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%A8%E8%AE%BA%E8%AF%BE%E3%80%8A%E4%B8%80%E3%80%8B/"/>
    <id>https://minning.github.io/2016/12/15/数据挖掘讨论课《一》/</id>
    <published>2016-12-15T03:17:53.000Z</published>
    <updated>2016-12-16T04:37:03.474Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p></p><p>为了增进对机器学习算法的学习，目前暂定一周一次讨论课，这里主要对课上的讨论结果进行记录，以增进记忆，方便日后查看学习</p>
<h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><p></p><p>本次讨论课的题目及解答如下所示：<br><br></p>
<p></p><h5>1、逻辑回归估计参数时的目标函数。[百度 2016 校招]<br>    <br>&emsp;&emsp;<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/" target="_blank" rel="external">http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/</a><p></p>
<p></p><h5>2、逻辑回归估计参数时的目标函数 如果加上一个先验的服从高斯分布的假设，会是什么样<p></p>
<p></p><h5>3、SVM在哪个地方引入的核函数<p></p>
<p></p><h5>4、如果用高斯核可以升到多少维?<p></p>
<p></p><h5>5、什么是贝叶斯估计<p></p>
<p></p><h5>6、k折交叉验证 中k取值多少有什么关系，bias，variance是什么？<p></p>
<p></p><h5>7、逻辑回归的值表示概率吗？<p></p>
<p></p><h5>8、分类模型和回归模型的区别<p></p>
<p></p><h5>9、分类模型可以做回归分析吗？反过来可以吗？<p></p>
<p><br><br><br></p>
<p></p><h5>1、SVM的原理推导   [美团 2016 校招]<br>    <br>&emsp;&emsp; <a href="http://blog.sina.com.cn/s/blog_4298002e010144k8.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4298002e010144k8.html</a><p></p>
<p></p><h5>2、讲一下random forest 和 GBDT的区别<p></p>
<p></p><h5>3、特征选取怎么选？ 为什么信息增益可以用来选特征？<p></p>
<p></p><h5>4、倒排索引的原理<p></p>
<p><br><br></p>
<p>考虑两个分类器：1）核函数取二次多项式的SVM分类器和2）没有约束的高斯混合模型（每个类别为一个高斯模型）。我们对R2空间的点进行两类分类。假设数据完全可分，SVM分类器中不加松弛惩罚项，并且假设有足够多的训练数据来训练高斯模型的协方差。下面说法正确的是？<br>A.SVM的VC维大于高斯混合模型的VC维<br>B.SVM的VC维小于高斯混合模型的VC维<br>C.两个分类器的结构风险值相同<br>D.这两个分类器的VC维相同</p>
<p><br><br></p>
<p>下面说法正确的是？<br>A.梯度下降有时会陷于局部极小值，但ＥＭ算法不会。<br>B.ＳＶＭ对噪声鲁棒。<br>C.当训练数据较多时更容易发生过拟合。<br>D.给定ｎ个数据点，如果其中一半用于训练，另一半用于测试，则训练误差和测试误差之间的差别会随着ｎ的增加而减小。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p></p><p>通过这次讨论课的学习，对这些常用的算法有了更深的理解，日后还会多准备这样的题目进行讨论，从而通过准备、讨论的过程更好的学习机器学习知识，巩固基础</p>
<p></p></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了增进对机器学习算法的学习，目前暂定一周一次讨论课，这里主要对课上的讨论结果进行记录，以增进记忆，方便日后查看学习&lt;/p&gt;

    
    </summary>
    
    
      <category term="机器学习校招" scheme="https://minning.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A0%A1%E6%8B%9B/"/>
    
  </entry>
  
</feed>
