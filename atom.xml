<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>minning</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://minning.github.io/"/>
  <updated>2017-03-07T08:40:41.638Z</updated>
  <id>https://minning.github.io/</id>
  
  <author>
    <name>minning</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>leetcode 35 Search Insert Position</title>
    <link href="https://minning.github.io/2017/03/07/leetcode-35-Search-Insert-Position/"/>
    <id>https://minning.github.io/2017/03/07/leetcode-35-Search-Insert-Position/</id>
    <published>2017-03-07T08:16:31.000Z</published>
    <updated>2017-03-07T08:40:41.638Z</updated>
    
    <content type="html"><![CDATA[<p>Leetcode 算法题 53<br><a href="https://leetcode.com/problems/search-insert-position/?tab=Description" target="_blank" rel="external">https://leetcode.com/problems/search-insert-position/?tab=Description</a></p>
<p><strong>题目描述</strong>：给定一个排序后的数组array和一个目标值target，如果target在array中出现的话，就返回其在array中的索引，如果没有的话就返回其在array中按顺序插入的话应该插入的位置。假定数组中没有重复的元素</p>
<p><strong>解题思路</strong>：这是一个典型的二分查找的问题，二分查找要求数组有序，二分查找的思想是每次查找指定数组中间节点的值，将其和target进行比较，如果命中则返回其索引，如果中间节点的值比target大，则将指定数组往左转移，即查找左边的数组，如果中间节点的值比target小，则查找右边的数组。<br>对于没有命中的情况，由于中止了循环，意味着指定数组的右指针往左偏移超过了左指针，因此可以返回右节点加1的值作为target的索引值。</p>
<p><strong>Python代码如下</strong></p>
<pre><code>class Solution(object):
    def searchInsert(self, nums, target):
        &quot;&quot;&quot;
        :type nums: List[int]
        :type target: int
        :rtype: int
        &quot;&quot;&quot;
        left = 0
        right = len(nums) - 1
        mid = (left + right) / 2

        while left &lt;= right:
            if nums[mid] == target:
                return mid
            elif nums[mid] &gt; target:
                right = mid - 1
                mid = (left + right) / 2
            elif nums[mid] &lt; target:
                left = mid + 1
                mid = (left + right) / 2
        return right + 1
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leetcode 算法题 53&lt;br&gt;&lt;a href=&quot;https://leetcode.com/problems/search-insert-position/?tab=Description&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https:/
    
    </summary>
    
    
      <category term="leetcode" scheme="https://minning.github.io/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>leetcode 53 Maximumsubarray</title>
    <link href="https://minning.github.io/2017/03/07/leetcode-53-Maximumsubarray/"/>
    <id>https://minning.github.io/2017/03/07/leetcode-53-Maximumsubarray/</id>
    <published>2017-03-07T07:18:03.000Z</published>
    <updated>2017-03-07T08:40:35.445Z</updated>
    
    <content type="html"><![CDATA[<p>leetcode算法题53：<br>求解最大连续子序列和<br><a href="https://leetcode.com/problems/maximum-subarray/?tab=Description" target="_blank" rel="external">https://leetcode.com/problems/maximum-subarray/?tab=Description</a></p>
<p><strong>题目描述</strong>：找出一个序列的连续子序列元素相加最大值</p>
<p><strong>解题思路</strong>：使用动态规划的思想，从左到右扫描序列，将新节点的值和之前的连续序列节点和相加与之前的连续节点和作比较，更大者作为最大值，如果相加后小于0,则将和设为0继续往后扫描，即舍弃之前节点。<br>注意点：最开始初始化sum值时应设为系统表示最小值，预防序列内节点均为负产生错误结果</p>
<pre><code>class Solution(object):
    def maxSubArray(self, nums):
        &quot;&quot;&quot;
        :type nums: List[int]
        :rtype: int
        &quot;&quot;&quot;
        maxans = -1*(sys.maxint)-1
        sum = 0
        for index in range(len(nums)):
            sum = sum + nums[index]
            maxans = max(sum, maxans)
            if sum&lt;0:
                sum = 0
        return maxans
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;leetcode算法题53：&lt;br&gt;求解最大连续子序列和&lt;br&gt;&lt;a href=&quot;https://leetcode.com/problems/maximum-subarray/?tab=Description&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;
    
    </summary>
    
    
      <category term="leetcode" scheme="https://minning.github.io/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>leetcode 001 TwoSum</title>
    <link href="https://minning.github.io/2017/03/07/leetcode-001-TwoSum/"/>
    <id>https://minning.github.io/2017/03/07/leetcode-001-TwoSum/</id>
    <published>2017-03-07T04:56:45.000Z</published>
    <updated>2017-03-07T08:40:28.621Z</updated>
    
    <content type="html"><![CDATA[<p>准备开始刷leetcode上的算法题，并对相关内容进行记录<br>今天记录的是leetcode上编号为1的题目TwoSum<br>leetcode链接如下：<a href="https://leetcode.com/problems/two-sum/" target="_blank" rel="external">https://leetcode.com/problems/two-sum/</a></p>
<p><strong>题目描述</strong>：给定一个只包含整数的数组，返回由数组中两个数相加之和为target的下标，假定该数组中有且只有一个解，且每个元素只能使用一次<br>举例： nums=[2, 7, 11, 15], target = 9,<br>      返回[0,1]<br><strong>解题思路</strong>：<br>思路一：暴力解法，两次循环，复杂度n^2，不能通过<br>思路二：新建一个字典，将元素放进去，查找target-x是否在字典中，复杂度n<br>    以下给出了思路二的解法</p>
<pre><code>class Solution(object):
    def twoSum(self, nums, target):
        &quot;&quot;&quot;
        :type nums: List[int]
        :type target: int
        :rtype: List[int]
        &quot;&quot;&quot;
        ret = []
        for i in range(len(nums)):
            for j in range(i + 1, len(nums)):
                if nums[i] + nums[j] == target:
                    ret = [i, j]
                    return ret
        return ret
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;准备开始刷leetcode上的算法题，并对相关内容进行记录&lt;br&gt;今天记录的是leetcode上编号为1的题目TwoSum&lt;br&gt;leetcode链接如下：&lt;a href=&quot;https://leetcode.com/problems/two-sum/&quot; target=&quot;_b
    
    </summary>
    
    
      <category term="leetcode" scheme="https://minning.github.io/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://minning.github.io/2016/12/24/20161123/"/>
    <id>https://minning.github.io/2016/12/24/20161123/</id>
    <published>2016-12-24T08:27:57.204Z</published>
    <updated>2016-12-24T08:27:57.204Z</updated>
    
    <content type="html"><![CDATA[<p></p><p></p>
<p></p><h5>1、k折交叉验证 中k取值多少有什么关系（ML19.6)，bias，variance是什么(ML4.3)？<h5><br>    &ensp;&ensp;答：一般来说，对于机器学习任务，都会将数据集分为训练数据、验证数据。然而如何对数据集划分却要考虑很多方面的问题，如划分比例、数据成分统计特性等。这里提问中的K主要指的是划分比例的问题范畴。<br>    &ensp;&ensp;首先这里的K指的是将数据等分为k份，然后将其中的k-1份作为训练数据，一份做测试数据。<br>    &ensp;&ensp;然后，在对数据进行划分时得确保训练集和验证集的数据分布相同，即确保其统计特性一致。<br>    &ensp;&ensp;我们可以想象一下，一般来说，k越大训练数据越多，验证数据越少，即模型训练越充分,但是验证结果就越不精准，极端情况下k和样本数相同，即只留一个验证数据，leave one out。那样验证结果就很不精确了。所以k折交叉验证中验证结果好坏随着k增大而增大，然后再随着k增大而减小。<br>    &ensp;&ensp;在k折交叉验证中还有一种常见的方法就是，随机挑选出k-1份当训练、下次再随机挑选出k-1个做训练，这样经过多次k-1份的训练从而增加模型的效果。<br>    &ensp;&ensp;那么bias、variance又是什么呢，与此相对应的还有一个概念叫error，error指的是模型预测结果与实际值之间的误差，通常<br>error=bias+variance 。<br>Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。<p></p>
<p></p><h5>2、分类模型和回归模型的区别？（ML2.6）<h5><br>    &ensp;&ensp;1）首先分类模型和回归模型都是有监督学习<br>    &ensp;&ensp;2）从预测结果上来看，分类模型的结果是离散值，回归模型是连续值<br>    &ensp;&ensp;3）从训练数据上看，分类模型的标记是离散值，回归模型的标记是连续值<br>    &ensp;&ensp;4）一定程度上讲，分类和回归是可以相互转化的<p></p>
<p></p><h5>3、分类模型可以做回归分析吗？反过来可以吗？ML2.6<h5><br>    &ensp;&ensp;分类模型可以做回归分析，回归模型也可以做分类<br>    &ensp;&ensp;1）对于分类模型，如果把分类标签划分的足够多，足够细，即可类似转化为回归模型<br>    &ensp;&ensp;2）对于回归模型，只需要将回归预测结果划分到一定范围，属于该范围的回归值就划分到该分类区，通过这种方法就可以将回归模型转化为分类模型。<p></p>
</h5></h5></h5></h5></h5></h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;h5&gt;1、k折交叉验证 中k取值多少有什么关系（ML19.6)，bias，variance是什么(ML4.3)？&lt;h5&gt;&lt;br&gt;    &amp;ensp;&amp;ensp;答：一般来说，对于机器学习任务，都会将数据集分为训练数据、验证数据。然而如
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据挖掘讨论课《二》  逻辑回归</title>
    <link href="https://minning.github.io/2016/12/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%A8%E8%AE%BA%E8%AF%BE%E3%80%8A%E4%BA%8C%E3%80%8B/"/>
    <id>https://minning.github.io/2016/12/23/数据挖掘讨论课《二》/</id>
    <published>2016-12-23T03:17:53.000Z</published>
    <updated>2016-12-23T07:52:09.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p></p><p>第一部分是之前搜集的一些题目，所以这次的标题就为《二》咯<br>这一部分主要是讲解线性回归、逻辑回归的原理和一些常见校招题。</p>
<p>Logistic回归：<br>　　Logistic是用来分类的，是一种线性分类器，需要注意的地方有：<br>　　1. logistic函数表达式为：<br>　　<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" style="border:none;"><br>  <img src="http://www.forkosh.com/mathtex.cgi? \Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}"><br>  <img src="http://www.forkosh.com/mathtex.cgi? 在此处插入Latex公式"><br>　　其导数形式为：<br>　　<br>　　2. logsitc回归方法主要是用最大似然估计来学习的，所以单个样本的后验概率为：<br>　　<br>　　到整个样本的后验概率：<br>　　<br>　　其中：<br>　　<br>　　通过对数进一步化简为：<br>　　<br>　　3. 其实它的loss function为-l(θ)，因此我们需使loss function最小，可采用梯度下降法得到。梯度下降法公式为:<br>　　<br>　　<br>　　Logistic回归优点：<br>　　1、实现简单；<br>　　2、分类时计算量非常小，速度很快，存储资源低；<br>　　缺点：<br>　　1、容易欠拟合，一般准确度不太高<br>　　2、只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须线性可分；</p>
<p>　　线性回归：<br>　　线性回归才是真正用于回归的，而不像logistic回归是用于分类，其基本思想是用梯度下降法对最小二乘法形式的误差函数进行优化，当然也可以用normal equation直接求得参数的解，结果为：<br>　　<br>　　而在LWLR（局部加权线性回归）中，参数的计算表达式为:<br>　　<br>　　因为此时优化的是：<br>　　<br>　　由此可见LWLR与LR不同，LWLR是一个非参数模型，因为每次进行回归计算都要遍历训练样本至少一次。<br>　　线性回归优点：<br>　　实现简单，计算简单；<br>　　缺点：<br>　　不能拟合非线性数据；</p>
<p>参考资料：<br>[1] <a href="http://blog.sciencenet.cn/blog-520608-745856.html" target="_blank" rel="external">http://blog.sciencenet.cn/blog-520608-745856.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一部分是之前搜集的一些题目，所以这次的标题就为《二》咯&lt;br&gt;这一部分主要是讲解线性回归、逻辑回归的原理和一些常见校招题。&lt;
    
    </summary>
    
    
      <category term="机器学习校招" scheme="https://minning.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A0%A1%E6%8B%9B/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘讨论课《一》 校招题</title>
    <link href="https://minning.github.io/2016/12/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%A8%E8%AE%BA%E8%AF%BE%E3%80%8A%E4%B8%80%E3%80%8B/"/>
    <id>https://minning.github.io/2016/12/15/数据挖掘讨论课《一》/</id>
    <published>2016-12-15T03:17:53.000Z</published>
    <updated>2016-12-23T06:57:56.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p></p><p>为了增进对机器学习算法的学习，目前暂定一周一次讨论课，这里主要对课上的讨论结果进行记录，以增进记忆，方便日后查看学习</p>
<h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><p></p><p>本次讨论课的题目及解答如下所示：<br><br></p>
<p></p><h5>1、逻辑回归估计参数时的目标函数。[百度 2016 校招]<br>    <br>&emsp;&emsp;<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/" target="_blank" rel="external">http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/</a><p></p>
<p></p><h5>2、逻辑回归估计参数时的目标函数 如果加上一个先验的服从高斯分布的假设，会是什么样<p></p>
<p></p><h5>3、SVM在哪个地方引入的核函数<p></p>
<p></p><h5>4、如果用高斯核可以升到多少维?<p></p>
<p></p><h5>5、什么是贝叶斯估计<p></p>
<p></p><h5>6、k折交叉验证 中k取值多少有什么关系，bias，variance是什么？<p></p>
<p></p><h5>7、逻辑回归的值表示概率吗？<p></p>
<p></p><h5>8、分类模型和回归模型的区别<p></p>
<p></p><h5>9、分类模型可以做回归分析吗？反过来可以吗？<p></p>
<p><br><br><br></p>
<p></p><h5>1、SVM的原理推导   [美团 2016 校招]<br>    <br>&emsp;&emsp; <a href="http://blog.sina.com.cn/s/blog_4298002e010144k8.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4298002e010144k8.html</a><p></p>
<p></p><h5>2、讲一下random forest 和 GBDT的区别<p></p>
<p></p><h5>3、特征选取怎么选？ 为什么信息增益可以用来选特征？<p></p>
<p></p><h5>4、倒排索引的原理<p></p>
<p><br><br></p>
<p>考虑两个分类器：1）核函数取二次多项式的SVM分类器和2）没有约束的高斯混合模型（每个类别为一个高斯模型）。我们对R2空间的点进行两类分类。假设数据完全可分，SVM分类器中不加松弛惩罚项，并且假设有足够多的训练数据来训练高斯模型的协方差。下面说法正确的是？<br>A.SVM的VC维大于高斯混合模型的VC维<br>B.SVM的VC维小于高斯混合模型的VC维<br>C.两个分类器的结构风险值相同<br>D.这两个分类器的VC维相同</p>
<p><br><br></p>
<p>下面说法正确的是？<br>A.梯度下降有时会陷于局部极小值，但ＥＭ算法不会。<br>B.ＳＶＭ对噪声鲁棒。<br>C.当训练数据较多时更容易发生过拟合。<br>D.给定ｎ个数据点，如果其中一半用于训练，另一半用于测试，则训练误差和测试误差之间的差别会随着ｎ的增加而减小。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p></p><p>&emsp;&emsp;这一部分主要是近期整理的一些机器学习数据挖掘相关的校招题，日后大概每周会进行一次校招题讲解，旨在深入理解常用的机器学习算法，加强机器学习基本功。</p>
<p></p></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了增进对机器学习算法的学习，目前暂定一周一次讨论课，这里主要对课上的讨论结果进行记录，以增进记忆，方便日后查看学习&lt;/p&gt;

    
    </summary>
    
    
      <category term="机器学习校招" scheme="https://minning.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A0%A1%E6%8B%9B/"/>
    
  </entry>
  
</feed>
