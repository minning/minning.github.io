<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>数据挖掘讨论课《一》 | minning</title>
  <meta name="description" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="minning">

  
  
  <link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="atom.xml">
  
  

  
</head>


<body class="post-template">

  <header class="site-head" >
    <div class="vertical">
        <div class="site-head-content inner">
            
            <h1 class="blog-title">minning</h1>
            <h2 class="blog-description"></h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2016-12-15T03:17:53.000Z" itemprop="datePublished">
          2016-12-15
      </time>
    
    
    | 
    <a href='/tags/机器学习校招/'>机器学习校招</a>
    
    
</span>
    <h1 class="post-title">数据挖掘讨论课《一》</h1>
    <section class="post-content">
      <h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p></p><p>为了增进对机器学习算法的学习，目前暂定一周一次讨论课，这里主要对课上的讨论结果进行记录，以增进记忆，方便日后查看学习</p>
<h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><p></p><p>本次讨论课的题目及解答如下所示：<br><br></p>
<p></p><h5>1、逻辑回归估计参数时的目标函数。[百度 2016 校招]<br>    <br>&emsp;&emsp;<a href="http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/" target="_blank" rel="external">http://kubicode.me/2015/08/16/Machine%20Learning/Algorithm-Summary-for-Interview/</a><p></p>
<p></p><h5>2、逻辑回归估计参数时的目标函数 如果加上一个先验的服从高斯分布的假设，会是什么样<p></p>
<p></p><h5>3、SVM在哪个地方引入的核函数<p></p>
<p></p><h5>4、如果用高斯核可以升到多少维?<p></p>
<p></p><h5>5、什么是贝叶斯估计<p></p>
<p></p><h5>6、k折交叉验证 中k取值多少有什么关系，bias，variance是什么？<p></p>
<p></p><h5>7、逻辑回归的值表示概率吗？<p></p>
<p></p><h5>8、分类模型和回归模型的区别<p></p>
<p></p><h5>9、分类模型可以做回归分析吗？反过来可以吗？<p></p>
<p><br><br><br></p>
<p></p><h5>1、SVM的原理推导   [美团 2016 校招]<br>    <br>&emsp;&emsp; <a href="http://blog.sina.com.cn/s/blog_4298002e010144k8.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4298002e010144k8.html</a><p></p>
<p></p><h5>2、讲一下random forest 和 GBDT的区别<p></p>
<p></p><h5>3、特征选取怎么选？ 为什么信息增益可以用来选特征？<p></p>
<p></p><h5>4、倒排索引的原理<p></p>
<p><br><br></p>
<p>考虑两个分类器：1）核函数取二次多项式的SVM分类器和2）没有约束的高斯混合模型（每个类别为一个高斯模型）。我们对R2空间的点进行两类分类。假设数据完全可分，SVM分类器中不加松弛惩罚项，并且假设有足够多的训练数据来训练高斯模型的协方差。下面说法正确的是？<br>A.SVM的VC维大于高斯混合模型的VC维<br>B.SVM的VC维小于高斯混合模型的VC维<br>C.两个分类器的结构风险值相同<br>D.这两个分类器的VC维相同</p>
<p><br><br></p>
<p>下面说法正确的是？<br>A.梯度下降有时会陷于局部极小值，但ＥＭ算法不会。<br>B.ＳＶＭ对噪声鲁棒。<br>C.当训练数据较多时更容易发生过拟合。<br>D.给定ｎ个数据点，如果其中一半用于训练，另一半用于测试，则训练误差和测试误差之间的差别会随着ｎ的增加而减小。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p></p><p>通过这次讨论课的学习，对这些常用的算法有了更深的理解，日后还会多准备这样的题目进行讨论，从而通过准备、讨论的过程更好的学习机器学习知识，巩固基础</p>
<p></p></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5></h5>
    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>minning</h4>
    <p></p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=https://minning.github.io/2016/12/15/数据挖掘讨论课《一》/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://minning.github.io/2016/12/15/数据挖掘讨论课《一》/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=https://minning.github.io/2016/12/15/数据挖掘讨论课《一》/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2016/12/15/数据挖掘讨论课《二》/">
        ← 数据挖掘讨论课《二》
    </a>
    
    <span class="page-number">•</span>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <a class="subscribe icon-feed" href="atom.xml"><span class="tooltip">Subscribe!</span></a>
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">minning</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>




<link rel="stylesheet" href="/modules/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/modules/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
    (function($){

        var wrapAll = function(q) {
            $(q).each( function() {
                var $img = $(this),
                        href = $img.attr('src');
                $img.wrap('<a rel="fancybox" href="' + href + '" title="' + $img.attr('alt') + '" class="link"></a>');
            });
        };

        wrapAll('.post-content img');
        wrapAll('.post-excerpt img');
        $('[rel="fancybox"]').fancybox();
    })(jQuery);
</script>



</body>
</html>
